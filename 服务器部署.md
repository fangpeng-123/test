### 服务器部署模型

##### 部署指令：

```bash
vllm serve /home/fp/.cache/modelscope/hub/models/Qwen/Qwen3-8B \
  --served-model-name Qwen3-8B \
  --host 0.0.0.0 \		
  --port 9000 \								# 端口
  --dtype half \
  --gpu-memory-utilization 0.9 \
  --max-model-len 8192 \
  --tensor-parallel-size 1 \
  --api-key "123456" \						# 指定密钥
  --enable-mixed-precision

```



##### 调用示例：

```bash
curl -N   -H "Content-Type: application/json"   -H "Authorization: Bearer 123456"   http://127.0.0.1:9000/v1/chat/completions   -d '{
        "model": "Qwen3-8B",
        "messages": [{"role": "user", "content": "用一句话介绍自己"}],
        "stream": true,
        "max_tokens": 4096
      }'

```

