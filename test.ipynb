{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置Serpapi密钥\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-b594b133f3274e368d577ea68e09e256\"  \n",
    "\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi(model_name=\"qwen-turbo\")\n",
    "\n",
    "print(llm.invoke(\"请介绍一下YOLO模型\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"d33b4179de64636c6325a1fb136299c505cded7a3dcd43d3609c89d551457565\"\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "llm = Tongyi(temperature=0, max_tokens=2048)\n",
    "\n",
    "tools = load_tools([\"serpapi\"])\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agent.run(\"今天合肥天气怎么样\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import Tongyi\n",
    "\n",
    "loader = UnstructuredFileLoader(\"/media/yls/1T硬盘7/文档/test.txt\")\n",
    "\n",
    "document = loader.load()\n",
    "print(f'document:{len(document)}')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "split_document = text_splitter.split_documents(document)\n",
    "print(f'document:{len(split_document)}')\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "chain.run(split_document[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "loader = DirectoryLoader('/media/yls/1T硬盘7/文档/', 'test.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), return_source_documents=True)\n",
    "\n",
    "result = qa({\"query\" : \"令狐冲学习了哪些技能\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "docsearch = Chroma.from_documents(documents, embeddings, persist_directory=\"/media/yls/1T硬盘7/文档/Chroma_db\")\n",
    "docsearch.persist()\n",
    "\n",
    "docsearch = Chroma(persist_directory=\"/media/yls/1T硬盘7/文档/Chroma_db\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-b594b133f3274e368d577ea68e09e256\"\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
    "\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.prompts.chat import(\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=Dj60HHy-Kqk')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 20\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "system_template = \"\"\"\n",
    "Use the following context to answer the user's question.\n",
    "If you don't know the answer, say you don't, don't try to make it up. And answer in Chinese.\n",
    "-----------\n",
    "{question}\n",
    "-----------\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template('{question}')\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "llm = Tongyi(model_name = \"qwen-turbo\", temperature=0.1, max_tokens=2048)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, condense_question_prompt=prompt)\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "    question = input('问题：')\n",
    "    result = qa({'question':question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = llm(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)\n",
    "resp = chat(chat_prompt_with_values.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = ''\n",
    "\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from langchain.utilities.zapier import ZapierNLAWrapper\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "zapier = ZapierNLAWrapper()\n",
    "toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
    "agent = initialize_agent(toolkit.get_tools(), llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "for tool in toolkit.get_tool():\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "agent.run('请用中文总结最后一封\"******@qq.com\"发给我的邮件。并将总结发送给\"******@qq.com\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Tongyi\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "template = \"\"\"Your job is to come up with a classis dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)\n",
    "review = overall_chain.run(\"Rome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Tongyi\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"this is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "output_parsers = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parsers.get_format_instructions()\n",
    "\n",
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcome to hefei!\")\n",
    "llm_out = llm(promptValue)\n",
    "\n",
    "output_parsers.parse(llm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-b594b133f3274e368d577ea68e09e256\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.chains import LLMRequestsChain, LLMChain\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "\n",
    "template = \"\"\"在 >>> 和 <<< 之间的是网页的返回的HTML内容。\n",
    "网页是新浪财经A股上市公司的公司简介。\n",
    "请抽取参数请求的信息\n",
    "\n",
    ">>> {requests_result} <<<\n",
    "请使用如下的JSON格式返回数据\n",
    "{{\n",
    "  \"company_name\":\"a\",\n",
    "  \"company_english_name\":\"b\",\n",
    "  \"issue_price\":\"c\",\n",
    "  \"date_of_establishment\":\"d\",\n",
    "  \"registered_capital\":\"e\",\n",
    "  \"office_address\":\"f\",\n",
    "  \"Company_profile\":\"g\"\n",
    "\n",
    "}}\n",
    "Extracted:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"requests_result\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=prompt))\n",
    "inputs = {\n",
    "    \"url\": \"https://vip.stock.finance.sina.com.cn/corp/go.php/vCI_CorpInfo/stockid/600519.phtml\"\n",
    "}\n",
    "\n",
    "response = chain(inputs)\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-b594b133f3274e368d577ea68e09e256\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"d33b4179de64636c6325a1fb136299c505cded7a3dcd43d3609c89d551457565\"\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.llms import Tongyi\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "\n",
    "llm = Tongyi(model_name = \"qwen-turbo\")\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func = search.run,\n",
    "        description = \"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Calculator\",\n",
    "        func = llm_math_chain,\n",
    "        description = \"useful for when you need to answer questions about math\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agent.run(\"who is Leo DiCaprio's girlfriend? what is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-b594b133f3274e368d577ea68e09e256\"\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatTongyi\n",
    "\n",
    "chat = ChatTongyi(model_name = \"qwen-turbo\", temperature=0)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"你好！\")\n",
    "history.add_ai_message(\"中国首都是哪里？\")\n",
    "\n",
    "ai_response = chat.invoke(history.messages)\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用在线 Hugging Face 模型\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = ''\n",
    "\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-x1\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm) \n",
    "\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face 模型拉取到本地\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = 'google/flan-t5-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "print(local_llm('What is the capital of France?'))\n",
    "\n",
    "template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n",
    "question = \"What is the capital of England?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms import Tongyi\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///../notebooks/Chinook.db\")\n",
    "toolkit = SQLDatabaseToolkit(db=db)\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=Tongyi(model_name = \"qwen-turbo\", temperature=0),\n",
    "    toolkit=toolkit,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor.run(\"Describe the playlisttrack table\")\n",
    "\n",
    "from langchain import Tongyi, SQLDatabase, SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+pymysql://root:root@127.0.0.1/chinook\")\n",
    "llm = Tongyi(model_name = \"qwen-turbo\", temperature=0)\n",
    "\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbase=True)\n",
    "db_chain.run(\"How many employees are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = init_chat_model(\n",
    "    model = \"Qwen/Qwen3-8B\",\n",
    "    model_provider = \"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "base_qa_chain = model | StrOutputParser()\n",
    "\n",
    "question = \"你好，请介绍一下自己。\"\n",
    "result = base_qa_chain.invoke(question)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser       # langchain_core中最简单的结构化解析器\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = init_chat_model(\n",
    "    model = \"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个乐于助人的助手， 请根据用户的问题给出答案\"),\n",
    "    (\"user\", \"这是用户的问题：{topic}, 请用 yes 或 no 回答\")\n",
    "])\n",
    "\n",
    "base_qa_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"is one plus one bigger than two?\"\n",
    "result = base_qa_chain.invoke(question)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.output_parsers import BooleanOutputParser        # Langchain 中将LLM输出解析为布尔值的基础类型解析器\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个乐于助人的助手， 请根据用户的问题给出答案\"),\n",
    "    (\"user\", \"这是用户的问题：{topic}, 请用 yes 或 no 回答\")\n",
    "])\n",
    "\n",
    "bool_qa_chain = prompt | model | BooleanOutputParser()\n",
    "\n",
    "question = \"is one plus one bigger than two?\"\n",
    "result = bool_qa_chain.invoke(question)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "schemes = [\n",
    "    ResponseSchema(name=\"name\", description=\"用户的姓名\"),\n",
    "    ResponseSchema(name=\"age\", description=\"用户的年龄\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemes)\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下内容提取用户信息，并返回 JSON 格式：\\n{input}\\n\\n{format_instructions}\"    \n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "raw = model.invoke(prompt.format_prompt(\n",
    "    input=\"用户叫李雷，今年25岁，是一名工程师。\",\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ").to_string())\n",
    "print(\"原始返回：\", raw.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\\n\\n标题：{title}\"\n",
    ")\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "schemes = [\n",
    "    ResponseSchema(name=\"time\", description=\"时间发生的时间\"),\n",
    "    ResponseSchema(name=\"location\", description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\", description=\"发生的具体事件\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemes)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"开源大模型的最新消息\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "schemes = [\n",
    "    ResponseSchema(name=\"name\", description=\"用户姓名\"),\n",
    "    ResponseSchema(name=\"age\", description=\"用户年龄\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemes)\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下内容提取用户信息，并返回 JSON 格式：\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\": \"用户李雷，今年25岁，是一名工程师。\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def debug_print(x):\n",
    "    print('中间结果（新闻正文）：', x)\n",
    "    return x\n",
    "\n",
    "debug_print = RunnableLambda(debug_print)\n",
    "\n",
    "full_chain = news_chain | debug_print | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"苹果公司在加州发布新款AI芯片\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"你叫苍井空，是日本著名女演员\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "chain = chat_prompt | model | StrOutputParser()\n",
    "\n",
    "result = chain.invoke(\"你好，清介绍一下自己\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessage(content=\"你叫迪丽热巴，是一名中国女演员。\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "message_list = []\n",
    "print(\"输入 exit 结束对话\")\n",
    "while True:\n",
    "    user_query = input(\"你：\")\n",
    "    if user_query.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    message_list.append(HumanMessage(content=user_query))\n",
    "\n",
    "    assistant_reply = chain.invoke({\"message\": message_list})\n",
    "    print(\"迪丽热巴：\", assistant_reply)\n",
    "\n",
    "    message_list.append(AIMessage(content=assistant_reply))\n",
    "\n",
    "    message_list = message_list[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessage(content=\"你叫迪丽热巴，是一名中国女演员。\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "message_list = []\n",
    "print(\"输入 exit 结束对话\")\n",
    "while True:\n",
    "    user_query = input(\"你：\")\n",
    "    if user_query.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    message_list.append(HumanMessage(content=user_query))\n",
    "\n",
    "    assistant_reply = ''\n",
    "    print('迪丽热巴：', end='')\n",
    "    for chunk in chain.stream({\"message\": message_list}):\n",
    "        assistant_reply+=chunk\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    print()\n",
    "\n",
    "    message_list.append(AIMessage(content=assistant_reply))\n",
    "\n",
    "    message_list = message_list[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 初始化模型\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url = \"https://api.siliconflow.cn/v1/\",\n",
    "    api_key = \"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    "    # 模型配置 Temperature、Top_p、 Top_k参数\n",
    "    temperature = 1.0,\n",
    "    # top_k = 0.6,\n",
    "    top_p = 1,\n",
    "    # num_predict = 2048\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"你是一个智能聊天机器人名叫方方\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 配置连续问答\n",
    "async def respond(user_msg: str, chat_hist: list, message_list: list):\n",
    "    # 输入为空直接返回\n",
    "    if not user_msg.strip():\n",
    "        yield \"\", chat_hist, message_list\n",
    "        return \n",
    "    \n",
    "    # 追加用户消息\n",
    "    message_list.append(HumanMessage(content=user_msg))\n",
    "    chat_hist = chat_hist + [(user_msg, None)]\n",
    "    yield \"\", chat_hist, message_list\n",
    "\n",
    "    # 流式调用模型\n",
    "    partial = \"\"\n",
    "    async for chunk in chain.astream({\"messages\": message_list}):\n",
    "        partial += chunk\n",
    "        chat_hist[-1] = (user_msg, partial)\n",
    "        yield \"\", chat_hist, message_list\n",
    "\n",
    "    # 完整恢复加入历史， 裁剪到附近 50 条\n",
    "    message_list.append(AIMessage(content=partial))\n",
    "    message_list = message_list[-50:]\n",
    "    \n",
    "    yield \"\", chat_hist, message_list\n",
    "\n",
    "def clear_history():\n",
    "    return [], \"\", []\n",
    "\n",
    "\n",
    "question = input(\"请输入你想询问的问题\")\n",
    "\n",
    "result = chain.invoke(question)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_experimental.tools import PythonAstREPLTool #从LangChain依赖库中引入Python代码解释器\n",
    "\n",
    "df = pd.read_csv('global_cities_data.csv')\n",
    "tool = PythonAstREPLTool(locals={\"df\":df})  # 传递给代码解释器的局部变量，这里时读取表格内容的pandas对象\n",
    "res = tool.invoke(\"df['GDP_Billion_USD].mean()\")    # 计算变量GDP的均值\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "df = pd.read_csv(\"global_cities_data.csv\")\n",
    "tool = PythonAstREPLTool(locals={\"df\": df})\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "system = f\"\"\"\n",
    "你可以访问一个名为 `df` 的 pandas 数据框，你可以使用df.head().to_markdown() 查看数据集的基本信息， \\\n",
    "请根据用户提出的问题，编写 Python 代码来回答。只返回代码，不返回其他内容。只允许使用 pandas 和内置库。\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", system),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "\n",
    "llm_with_tools = model.bind_tools([tool])\n",
    "\n",
    "llm_chain = prompt | llm_with_tools | parser | tool\n",
    "\n",
    "response = llm_chain.invoke(\n",
    "    \"我有一张表，名为'df'，请帮我计算GDP_Billion_USD字段的均值。\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "        查询即时天气函数\n",
    "        :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "        :return：心知天气 API查询即时天气的结果，具体URL请求地址为：\"https://api.seniverse.com/v3/weather/now.json\"\n",
    "        返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    url = \"https://api.seniverse.com/v3/weather/now.json\"\n",
    "    params = {\n",
    "        \"key\": \"SUaojvLPfSQJD9N4k\",\n",
    "        \"location\": loc,\n",
    "        \"language\": \"zh-Hans\",\n",
    "        \"unit\": \"c\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    temperature = response.json()\n",
    "    return temperature['results'][0]['now']\n",
    "\n",
    "print(get_weather('合肥'))\n",
    "print(get_weather.description)\n",
    "print(get_weather.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    ")\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=get_weather.name, first_tool_only=True)\n",
    "\n",
    "llm_chain = llm_with_tools | parser\n",
    "\n",
    "get_weather_chain = llm_chain | get_weather\n",
    "response = get_weather_chain.invoke(\"请问上海今天天气如何?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-bb8c007d0a8c4dfca31dfac49b897976\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个智能助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好\"},\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(response.choices[0].messages.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent, tool, AgentExecutor\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建查询天气工具\n",
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "        查询即时天气函数\n",
    "        :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "        :return：心知天气 API查询即时天气的结果，具体URL请求地址为：\"https://api.seniverse.com/v3/weather/now.json\"\n",
    "        返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    url = \"https://api.seniverse.com/v3/weather/now.json\"\n",
    "    params = {\n",
    "        \"key\": \"SUaojvLPfSQJD9N4k\",\n",
    "        \"location\": loc,\n",
    "        \"language\": \"zh-Hans\",\n",
    "        \"unit\": \"c\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    temperature = response.json()\n",
    "    return temperature['results'][0]['now']\n",
    "\n",
    "# 定义写文件工具\n",
    "@tool\n",
    "def write_file(content):\n",
    "    \"\"\"\n",
    "    将指定内容写入本地文件。\n",
    "    :param content: 必要参数，字符串类型，用于表示需要写入文档的具体内容。\n",
    "    :return：是否成功写入\n",
    "    \"\"\"\n",
    "    with open('/media/yls/1T硬盘4/code/Agent/res.txt','w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    return \"已经写入本地文件\"\n",
    "\n",
    "# 定义工具\n",
    "tools = [get_weather, write_file]\n",
    "\n",
    "# 设置系统提示词\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是天气助手，请根据用户的问题，给出相应的天气信息,并具备将结果写入文件的能力\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 初始化大模型\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    ")\n",
    "\n",
    "# 创建代理\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "# 运行当前代理\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # Verbose表示是否打印执行细节\n",
    "response = agent_executor.invoke({\"input\":\"查一下今天合肥和杭州今天天气怎么样，并将结果写入本地的文件中。\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # 会自动加载 .env 文件中的环境变量\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "model = init_chat_model(\n",
    "    model='Qwen/Qwen3-8B',\n",
    "    model_provider='openai',\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一名助人为乐的助手，并且可以调用工具进行网络搜索，获取实时信息\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"请问苹果2025WWDC发布会召开的时间是？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import requests\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, tool, AgentExecutor\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "search = TavilySearchResults(max_results=1)\n",
    "\n",
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "        查询即时天气函数\n",
    "        :param loc: 必要函数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "        :return: 心知天气 API 查询即时天气的结果，具体URL请求地址为：\"https://api.seniverse.com/v3/weather/now.json\"\n",
    "        返回结果对象类型为解析之后的JSON对象，并用字符串形式进行，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://api.seniverse.com/v3/weather/now.json\"\n",
    "    params = {\n",
    "        \"key\": \"\",\n",
    "        \"location\": \"\",\n",
    "        \"language\": \"zh-Hans\",\n",
    "        \"unit\": \"c\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    temperature = response.json()\n",
    "    return temperature['results'][0]['now']\n",
    "\n",
    "@tool\n",
    "def write_file(content):\n",
    "    \"\"\"\n",
    "    将指定内容写入本地文件。\n",
    "    :param content；必要的参数，字符串类型， 用于表示需要写入文档的具体内容。\n",
    "    :return: 是否成功写入\n",
    "    \"\"\"\n",
    "    with open('', 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    return \"已成功写入本地文件\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是天气助手，请根据用户的问题，给出相应的天气信息，并具备将结果写入文件的能力。并且可以调用工具进行网络搜索，获取实时信息。\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"\",\n",
    "    api_key=\"\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "tool = [get_weather, write_file, search]\n",
    "\n",
    "agent = create_tool_calling_agent(model, tool, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tool, verbose=True)\n",
    "response = agent_executor.invoke({\"input\":\"请问今天合肥的天气？并将查询结果写入本地文件\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 初始化 Playwright 浏览器：\n",
    "async def init_agent():\n",
    "    sync_browser = create_async_playwright_browser() # 创建同步执行的浏览器\n",
    "    toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser) # 构建 PlayWright 浏览器\n",
    "    tools =  toolkit.get_tools() # 获取 PlayWright 浏览器函数\n",
    "\n",
    "    # 初始化大模型\n",
    "    model = init_chat_model(\n",
    "        model=\"Qwen/Qwen3-8B\",\n",
    "        model_provider=\"openai\",\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    "    )\n",
    "\n",
    "    # 通过 Langchain Hub 拉取提示词,与自定义提示词等价\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"你是一个乐于助人的助手\"),\n",
    "#         (\"placeholder\", \"{chat_history}\"),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "    # 通过 Langchain 创建 OpenAI 工具代理\n",
    "    agent = create_openai_tools_agent(model, tools, prompt)\n",
    "\n",
    "    # 通过 AgentExecutor 执行代理\n",
    "    # executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    return AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor = await init_agent()\n",
    "result = await agent_executor.ainvoke({\n",
    "    \"input\": \"访问 https://www.microsoft.com/ 并总结标题\"\n",
    "})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# 以下依赖用于编写 PDF 创建写入相关代码\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_JUSTIFY, TA_CENTER\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def summarize_website(url):\n",
    "    \"\"\"访问指定网站并返回内容总结\"\"\"\n",
    "    try:\n",
    "        # 创建浏览器实例\n",
    "        sync_browser = create_async_playwright_browser()\n",
    "        toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser)\n",
    "        tools = toolkit.get_tools()\n",
    "\n",
    "        # 初始化模型和 Agent\n",
    "        model = init_chat_model(\n",
    "            model=\"Qwen/Qwen3-8B\",\n",
    "            model_provider=\"openai\",\n",
    "            base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "            api_key=\"sk-hcebbggeoucrpvxhtakviksgvfwpqpmixzjycqqfpahgcfqu\",\n",
    "        )\n",
    "        prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "        agent = create_openai_tools_agent(model, tools, prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "        # 执行总结任务\n",
    "        command = {\n",
    "            \"input\": f\"访问这个网站 {url} 并帮我详细总结一下这个网站的内容，包括主要功能、特点和使用方法\"\n",
    "        }\n",
    "\n",
    "        result = agent_executor.invoke(command)\n",
    "        return result.get(\"output\", \"无法获取网站内容\")\n",
    "    except Exception as e:\n",
    "        return f\"网站访问失败：{str(e)}\"\n",
    "\n",
    "@tool\n",
    "def generate_pdf(content):\n",
    "    \"\"\"将文本内容生成为PDF文件\"\"\"\n",
    "    try:\n",
    "        # 生成文件名（带时间戳）\n",
    "        timestamp =  datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"website_summary_{timestamp}.pdf\"\n",
    "\n",
    "        # 创建 PDF 文档\n",
    "        doc = SimpleDocTemplate(filename, pagesize=A4)\n",
    "        styles = getSampleStyleSheet()\n",
    "\n",
    "        # 注册中文字体（如果系统有的话）\n",
    "        try:\n",
    "            # Windows 系统字体路径\n",
    "            font_paths = [\n",
    "                \"C:/Windows/Fonts/simhei.ttf\",  # 黑体\n",
    "                \"C:/Windows/Fonts/simsun.ttc\",  # 宋体\n",
    "                \"C:/Windows/Fonts/msyh.ttc\",  # 微软雅黑\n",
    "            ]\n",
    "\n",
    "            chinese_font_registered = False\n",
    "            for font_path in font_paths:\n",
    "                if os.path.exists(font_path):\n",
    "                    try:\n",
    "                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))\n",
    "                        chinese_font_registered = True\n",
    "                        print(f\"✅ 成功注册中文字体: {font_path}\")\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "            if not chinese_font_registered:\n",
    "                print(\"❌ 未找到中文字体，使用默认字体\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 字体注册失败：{e}\")\n",
    "\n",
    "        # 自定义样式 - 支持中文\n",
    "        title_style = ParagraphStyle(\n",
    "           'CustomContent',\n",
    "           parent=styles['Normal'],\n",
    "           fontSize=11,\n",
    "           alignment=TA_JUSTIFY,\n",
    "           leftIndent=20,\n",
    "           rightIndent=20,\n",
    "           spaceAfter=12,\n",
    "           fontName='ChineseFont' if 'chinese_font_registered' in  locals() and chinese_font_registered else 'Helvetica-Bold'\n",
    "        )\n",
    "\n",
    "        content_style = ParagraphStyle(\n",
    "            'CustomContent',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=11,\n",
    "            alignment=TA_JUSTIFY,\n",
    "            leftIndent=20,\n",
    "            rightIndent=20,\n",
    "            spaceAfter=12,\n",
    "            fontName='ChineseFont' if 'chinese_font_registered' in locals() and chinese_font_registered else  'Helvetica'\n",
    "        )\n",
    "\n",
    "        # 构建 PDF 内容\n",
    "        story = []\n",
    "\n",
    "        # 标题\n",
    "        story.append(Paragraph(\"网站内容总结报告\", title_style))\n",
    "        story.append(Spacer(1, 20))\n",
    "\n",
    "        # 生成时间\n",
    "        time_text = f\"生成时间：{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        story.append(Paragraph(time_text, style=['Normal']))\n",
    "        story.append(Spacer(1, 20))\n",
    "\n",
    "        # 分割线\n",
    "        story.append(Paragraph(\"=\" * 50, styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "\n",
    "        # 主要内容 - 改进中文处理\n",
    "        if content:\n",
    "            # 清理和处理内容\n",
    "            content = content.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "            Paragraphs = content.split('\\n')\n",
    "\n",
    "            for para in Paragraphs:\n",
    "                # 处理特殊字符\n",
    "                clean_para = para.strip()\n",
    "                # 转换 HTML 实体\n",
    "                clean_para = clean_para.replace('&1t;', '<').replace('&gt;', '>').replace('&amp', '&')\n",
    "\n",
    "                try:\n",
    "                    story.append(Paragraph(clean_para, content_style))\n",
    "                    story.append(Spacer(1, 8))\n",
    "                except Exception as pars_error:\n",
    "                    # 如果段落没有问题，尝试使用默认字体\n",
    "                    try:\n",
    "                        fallback_style = ParagraphStyle(\n",
    "                            'Fallback',\n",
    "                            parent=styles['Normal'],\n",
    "                            fontSize=10,\n",
    "                            leftIndent=20,\n",
    "                            rightIndent=20,\n",
    "                            spaceAfter=10\n",
    "                        )\n",
    "                        story.append(Paragraph(clean_para, fallback_style))\n",
    "                        story.append(Spacer(1, 8))\n",
    "                    except:\n",
    "                        # 如果还是有问题，记录错误但继续\n",
    "                        print(f\"❌ 段落处理失败：{clean_para[:50]}...\")\n",
    "                        continue\n",
    "        else:\n",
    "            story.append(Paragraph(\"暂无内容\", content_style))\n",
    "        \n",
    "        # 页脚信息\n",
    "        story.append(Spacer(1, 30))\n",
    "        story.append(Paragraph(\"=\" * 50, style=['Normal']))\n",
    "        story.append(Paragraph(\"本报告由 Playwright PDF Agent 自动生成\", styles['Italic']))\n",
    "\n",
    "        # 生成 PDF\n",
    "        doc.build(story)\n",
    "\n",
    "        # 获取绝对路径\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        print(f\"📄 PDF 文件生成完成: {abs_path}\")\n",
    "        return f\"PDF 文件生成完成: {abs_path}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"PDF 生成失败：{str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    \n",
    "# 创建串行链\n",
    "print(\"=== 创建串行链：网站总结 → PDF 生成 ===\")\n",
    "\n",
    "simple_chain = summarize_website | generate_pdf\n",
    "\n",
    "# 编写测试函数\n",
    "def test_simple_chain(url):\n",
    "    \"\"\"测试简单串行链\"\"\"\n",
    "    print(f\"\\n🔄 开始处理 URL：{url}\")\n",
    "    print(\"📝 步骤1：网站总结...\")\n",
    "    print(\"📄 步骤2： 生成 PDF ...\")\n",
    "\n",
    "    result = simple_chain.invoke(url)\n",
    "    print(f\"✅ 完成：{result}\")\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试链接\n",
    "    test_url = \"https://www.microsoft.com/en-us/microsoft-365/blog/2025/01/16/copilot-is-now-included-in-microsoft-365-personal-and-family/?culture=zh-cn&country=cn\"\n",
    "    test_simple_chain(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funasr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
