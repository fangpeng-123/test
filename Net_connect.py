from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
import requests
# é…ç½®SerpApi Key
SERPAPI_KEY = "d33b4179de64636c6325a1fb136299c505cded7a3dcd43d3609c89d551457565"

def google_search(query):
    """
    ä½¿ç”¨ SerpAPI è¿›è¡Œ Google æœç´¢ï¼Œå¹¶è¿”å›å‰5ä¸ªç»“æœçš„æ ‡é¢˜å’Œæ‘˜è¦ã€‚
    """
    url = "https://serpapi.com/search"
    params = {
        "engine": "google",
        "q": query,
        "api_key": SERPAPI_KEY,
        "num": 5
    }

    response = requests.get(url, params=params)
    if response.status_code == 200:
        results = response.json().get("orangic_results", [])
        snippets = ""
        for res in results:
            title = res.get("title", "")
            snippet = res.get("snippets", "")
            snippets += f"ã€{title}ã€‘\n{snippet}\n\n"
        return snippets
    else:
        return "æ— æ³•è”ç½‘æœç´¢ç»“æœï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–è€… API Keyã€‚"
    
# åˆå§‹åŒ–å¤§æ¨¡å‹
ollm = OllamaLLM(model="qwen3:8b")

# å®šä¹‰æç¤ºæ¨¡æ¿
Prompt_Template = """
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†é—®ç­”åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æä¾›çš„ç½‘ç»œæœç´¢ç»“æœæ¥å›ç­”é—®é¢˜ã€‚

ã€ç½‘ç»œæœç´¢ç»“æœã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”¨ä¸­æ–‡ç®€æ´æ˜äº†åœ°å›ç­”ã€‚
"""

prompt = PromptTemplate.from_template(Prompt_Template)

# æ„å»ºLLM Chain
from langchain_core.runnables import RunnableSequence
chain = prompt | ollm

# æŸ¥è¯¢å‡½æ•°
def answer_question(question):
    context = google_search(question)
    response  =chain.invoke({"context": context, "question": question})
    return response

# æµ‹è¯•
if __name__ == "__main__":
    question = input("è¯·é—®ä½ æƒ³çŸ¥é“ä»€ä¹ˆï¼š")
    print("ğŸ” æ­£åœ¨è”ç½‘æœç´¢ä¸­...")
    answer = answer_question(question)
    print("\nğŸ“ å›ç­”ï¼š")
    print(answer)